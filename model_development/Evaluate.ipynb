{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "data_folder = '/media/QNAP/People/GongyuZhang/ROP/data/raw/image/'\n",
    "\n",
    "with open('../src/data/data_split.csv', 'r') as f:\n",
    "    content = list(csv.reader(f))\n",
    "    grading_header = content[0]\n",
    "    grading_data = content[1:]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'file'),\n",
       " (1, 'subset'),\n",
       " (2, 'CH'),\n",
       " (3, 'JT'),\n",
       " (4, 'KP'),\n",
       " (5, 'SB'),\n",
       " (6, 'GA'),\n",
       " (7, 'group')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(grading_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gradings = {}\n",
    "for row in grading_data:\n",
    "    for grader, grading in zip(grading_header[2:], row[2:]):\n",
    "        all_gradings[row[0], grader] = grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_classification_all_files.csv', 'r') as f:\n",
    "    content = list(csv.reader(f))\n",
    "    model_header = content[0]\n",
    "    model_data = content[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'file'), (1, 'model'), (2, 'normal'), (3, 'pre-plus'), (4, 'plus')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(model_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gradings = {}    \n",
    "for file, model, normal, pre_plus, plus in model_data:\n",
    "    model_gradings[file, model, 'normal'] = normal\n",
    "    model_gradings[file, model, 'pre-plus'] = pre_plus\n",
    "    model_gradings[file, model, 'plus'] = plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal_scores = {r[0]: float(r[2]) for r in model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_grading = {\n",
    "    'normal': {r[0]: float(r[2]) for r in model},\n",
    "    'pre-plus': {r[0]: float(r[3]) for r in model},\n",
    "    'plus': {r[0]: float(r[4]) for r in model},\n",
    "    'ungradable': {r[0]: 0 for r in model}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'file'),\n",
       " (1, 'subset'),\n",
       " (2, 'CH'),\n",
       " (3, 'JT'),\n",
       " (4, 'KP'),\n",
       " (5, 'SB'),\n",
       " (6, 'GA'),\n",
       " (7, 'group')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_grading = {r[0]: r[6] for r in grading}\n",
    "group_grading = {r[0]: r[7] for r in grading}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = 'normal', 'pre-plus', 'plus', 'ungradable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317875107348792"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = []\n",
    "pred = []\n",
    "for k, n in model_normal_scores.items():\n",
    "    if ga_grading[k] == 'ungradable':\n",
    "        continue\n",
    "    ref.append(1 if ga_grading[k] == 'normal' else 0) \n",
    "    pred.append(n) \n",
    "\n",
    "roc_auc_score(ref, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0.9317875107348792\n",
      "pre-plus 0.8174603174603174\n",
      "plus 0.9405956362478103\n"
     ]
    }
   ],
   "source": [
    "for label_name in label_names:\n",
    "    \n",
    "    ref = []\n",
    "    pred = []\n",
    "    for k, n in model_scores_grading[label_name].items():\n",
    "        ref.append(1 if ga_grading[k] == label_name else 0) \n",
    "        pred.append(n) \n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(ref, pred)\n",
    "    except:\n",
    "        continue\n",
    "    print(label_name, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0.9573999999999999\n",
      "pre-plus 0.7402351669144479\n",
      "plus 0.9489406500855375\n"
     ]
    }
   ],
   "source": [
    "for label_name in label_names:\n",
    "    \n",
    "    ref = []\n",
    "    pred = []\n",
    "    for k, n in model_scores_grading[label_name].items():\n",
    "        ref.append(1 if group_grading[k] == label_name else 0) \n",
    "        pred.append(n) \n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(ref, pred)\n",
    "    except:\n",
    "        continue\n",
    "    print(label_name, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [r[0] for r in model if r[1] == 'ensemble']\n",
    "ensemble_scores = {r[0]: ['normal', 'pre-plus', 'plus'][np.argmax([float(x) for x in r[2:]])]\n",
    "                   for r in model if r[1] == 'ensemble'}\n",
    "\n",
    "model_scores = np.array([ensemble_scores[filename] for filename in filenames])\n",
    "ga_scores = np.array([ga_grading[filename] for filename in filenames])\n",
    "group_scores = np.array([group_grading[filename] for filename in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import numpy as np\n",
    "\n",
    "def disp_table(reference_scores, obs_scores):\n",
    "    table = ''\n",
    "\n",
    "    \n",
    "    template = ('| ' + '{:12} | ' * (len(label_names) + 2) + '\\n' )\n",
    "    table += template.format(* (['ref \\ model'] + list(label_names) + ['']))\n",
    "    table += ' :-: '.join(['|'] * (len(label_names) + 3)) + '\\n' \n",
    "    totals = np.zeros(len(label_names))\n",
    "\n",
    "    for ref_name in label_names:\n",
    "        ref_items = reference_scores == ref_name\n",
    "        c = []\n",
    "        for obs_name in label_names:\n",
    "            obs_items = obs_scores == obs_name\n",
    "            c.append(np.count_nonzero(ref_items & obs_items))\n",
    "\n",
    "        totals += c\n",
    "        table += template.format(*([ref_name] + c + [sum(c)]))\n",
    "\n",
    "    table += template.format(*(['&nbsp;'] + list(totals) + ['']))\n",
    "\n",
    "    display(Markdown(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| ref \\ model  | normal       | pre-plus     | plus         | ungradable   |              | \n",
       "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
       "| normal       |          132 |            0 |           11 |            0 |          143 | \n",
       "| pre-plus     |           13 |            0 |            5 |            0 |           18 | \n",
       "| plus         |            9 |            0 |           30 |            0 |           39 | \n",
       "| ungradable   |            0 |            0 |            0 |            0 |            0 | \n",
       "| &nbsp;       |        154.0 |          0.0 |         46.0 |          0.0 |              | \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_table(ga_scores, model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| ref \\ model  | normal       | pre-plus     | plus         | ungradable   |              | \n",
       "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
       "| normal       |          100 |            0 |            0 |            0 |          100 | \n",
       "| pre-plus     |           41 |            0 |            8 |            0 |           49 | \n",
       "| plus         |           13 |            0 |           38 |            0 |           51 | \n",
       "| ungradable   |            0 |            0 |            0 |            0 |            0 | \n",
       "| &nbsp;       |        154.0 |          0.0 |         46.0 |          0.0 |              | \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_table(group_scores, model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| ref \\ model  | normal       | pre-plus     | plus         | ungradable   |              | \n",
       "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
       "| normal       |          100 |            0 |            0 |            0 |          100 | \n",
       "| pre-plus     |           29 |           15 |            5 |            0 |           49 | \n",
       "| plus         |           14 |            3 |           34 |            0 |           51 | \n",
       "| ungradable   |            0 |            0 |            0 |            0 |            0 | \n",
       "| &nbsp;       |        143.0 |         18.0 |         39.0 |          0.0 |              | \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_table(group_scores, ga_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
